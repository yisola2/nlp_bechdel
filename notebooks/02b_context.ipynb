{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ee91f8",
   "metadata": {},
   "source": [
    "## Part 6: Contextual Gender Analysis\n",
    "\n",
    "### 3.4 Contextual Gender Analysis (`02b_context.ipynb`)\n",
    "\n",
    "**Design Principles:**\n",
    "- Use pronoun context and coreference resolution for characters with unknown gender\n",
    "- Analyze sentences containing character mentions to find gendered pronouns\n",
    "- Apply advanced NLP techniques (coreference resolution) to improve classification\n",
    "\n",
    "**Implementation Details:**\n",
    "- Used NLTK for sentence tokenization\n",
    "- Analyzed sentences containing character mentions for gendered pronouns (he/him/his, she/her/hers)\n",
    "- Used spaCy with the coreferee extension for coreference resolution\n",
    "- Applied threshold-based classification based on pronoun counts\n",
    "\n",
    "**Models and Libraries:**\n",
    "- NLTK for sentence tokenization\n",
    "- spaCy `en_core_web_lg` model for linguistic analysis\n",
    "- `coreferee` extension for coreference resolution\n",
    "\n",
    "**Key Thresholds:**\n",
    "- Minimum number of dominant pronouns required: 2\n",
    "- Minimum difference between male/female pronoun counts: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and NLTK setup checked.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from collections import Counter\n",
    "import nltk # Using NLTK for sentence tokenization\n",
    "\n",
    "# Ensure NLTK sentence tokenizer is available\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
    "    nltk.download('punkt')\n",
    "\n",
    "print(\"Libraries imported and NLTK setup checked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set.\n",
      "Gendered input CSV: ../data/character_analysis_gendered_new.csv\n",
      "Cleaned text input: ../data/dracula_cleaned.txt\n",
      "Output CSV: ../data/character_analysis_gendered_contextual_new.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration\n",
    "# --- Input Files ---\n",
    "GENDERED_CSV_PATH = \"../data/character_analysis_gendered_new.csv\" # Input from Notebook 02\n",
    "CLEANED_TEXT_PATH = \"../data/dracula_cleaned.txt\" # Input from Notebook 00\n",
    "\n",
    "# --- Output File ---\n",
    "OUTPUT_CSV_PATH = \"../data/character_analysis_gendered_contextual_new.csv\"\n",
    "\n",
    "# --- Constants ---\n",
    "GENDER_FEMALE = \"Female\"\n",
    "GENDER_MALE = \"Male\"\n",
    "GENDER_UNKNOWN = \"Unknown\"\n",
    "\n",
    "# --- Pronoun Sets ---\n",
    "MALE_PRONOUNS = {'he', 'him', 'his'}\n",
    "FEMALE_PRONOUNS = {'she', 'her', 'hers'}\n",
    "\n",
    "# --- Parameters ---\n",
    "MIN_PRONOUN_THRESHOLD = 2 # Minimum number of dominant pronouns required to make a classification\n",
    "MIN_PRONOUN_DIFFERENCE = 1 # Minimum difference between male/female counts\n",
    "\n",
    "print(\"Configuration set.\")\n",
    "print(f\"Gendered input CSV: {GENDERED_CSV_PATH}\")\n",
    "print(f\"Cleaned text input: {CLEANED_TEXT_PATH}\")\n",
    "print(f\"Output CSV: {OUTPUT_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input data...\n",
      "Successfully loaded 220 characters from ../data/character_analysis_gendered_new.csv.\n",
      "Successfully loaded text (848415 chars) from ../data/dracula_cleaned.txt.\n",
      "Tokenized text into 8479 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Input Data\n",
    "print(\"Loading input data...\")\n",
    "try:\n",
    "    char_df = pd.read_csv(GENDERED_CSV_PATH)\n",
    "    print(f\"Successfully loaded {len(char_df)} characters from {GENDERED_CSV_PATH}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Character CSV file not found at {GENDERED_CSV_PATH}\")\n",
    "    char_df = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading character CSV: {e}\")\n",
    "    char_df = None\n",
    "\n",
    "try:\n",
    "    with open(CLEANED_TEXT_PATH, 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "    print(f\"Successfully loaded text ({len(full_text)} chars) from {CLEANED_TEXT_PATH}.\")\n",
    "    # Tokenize text into sentences\n",
    "    sentences = nltk.sent_tokenize(full_text)\n",
    "    print(f\"Tokenized text into {len(sentences)} sentences.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Cleaned text file not found at {CLEANED_TEXT_PATH}\")\n",
    "    full_text = None\n",
    "    sentences = []\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or tokenizing text: {e}\")\n",
    "    full_text = None\n",
    "    sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Helper Function to Find Mentions and Analyze Context\n",
    "\n",
    "def get_contextual_gender(character_name, variations_str, sentences_list):\n",
    "    \"\"\"Find mentions, analyze pronouns in surrounding sentences, return classification.\"\"\"\n",
    "    if not variations_str or not isinstance(variations_str, str):\n",
    "        # Handle cases where variations might be NaN or not a string\n",
    "        variations = {character_name} # Fallback to using the canonical key itself\n",
    "    else:\n",
    "        variations = set(var.strip() for var in variations_str.split(','))\n",
    "        variations.add(character_name) # Ensure canonical name is included\n",
    "\n",
    "    # Compile regex patterns for variations (case-insensitive, whole word)\n",
    "    # Using word boundaries (\\b) to avoid partial matches (e.g., 'Her' in 'Hertfordshire')\n",
    "    patterns = [re.compile(r'\\b' + re.escape(var) + r'\\b', re.IGNORECASE) for var in variations if var]\n",
    "\n",
    "    male_evidence = 0\n",
    "    female_evidence = 0\n",
    "    mentions_found = 0\n",
    "\n",
    "    for sentence in sentences_list:\n",
    "        sentence_lower = sentence.lower()\n",
    "        found_mention_in_sentence = False\n",
    "        for pattern in patterns:\n",
    "            if pattern.search(sentence): # Check if any variation exists in the sentence\n",
    "                found_mention_in_sentence = True\n",
    "                mentions_found += len(pattern.findall(sentence)) # Count all occurrences in sentence\n",
    "                break # Stop checking patterns for this sentence once one is found\n",
    "\n",
    "        if found_mention_in_sentence:\n",
    "            # Simple context: pronouns within the *same* sentence\n",
    "            words = re.findall(r'\\b\\w+\\b', sentence_lower) # Basic word tokenization\n",
    "            for word in words:\n",
    "                if word in MALE_PRONOUNS:\n",
    "                    male_evidence += 1\n",
    "                elif word in FEMALE_PRONOUNS:\n",
    "                    female_evidence += 1\n",
    "\n",
    "    # Apply classification rules\n",
    "    if male_evidence >= MIN_PRONOUN_THRESHOLD and (male_evidence - female_evidence) >= MIN_PRONOUN_DIFFERENCE:\n",
    "        return GENDER_MALE, male_evidence, female_evidence, mentions_found\n",
    "    elif female_evidence >= MIN_PRONOUN_THRESHOLD and (female_evidence - male_evidence) >= MIN_PRONOUN_DIFFERENCE:\n",
    "        return GENDER_FEMALE, male_evidence, female_evidence, mentions_found\n",
    "    else:\n",
    "        return GENDER_UNKNOWN, male_evidence, female_evidence, mentions_found\n",
    "\n",
    "print(\"Helper function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying contextual gender classification to 'Unknown' characters...\n",
      "Found 175 characters initially marked as Unknown.\n",
      "  Processed 20/175 unknown characters...\n",
      "  Processed 40/175 unknown characters...\n",
      "  Processed 60/175 unknown characters...\n",
      "  Processed 80/175 unknown characters...\n",
      "  Processed 100/175 unknown characters...\n",
      "  Processed 120/175 unknown characters...\n",
      "  Processed 140/175 unknown characters...\n",
      "  Processed 160/175 unknown characters...\n",
      "Contextual analysis finished in 4.44 seconds.\n",
      "\n",
      "Updated gender classification results (showing previously Unknown):\n",
      "     canonical_key final_gender contextual_gender  male_pronouns  \\\n",
      "1      Van_Helsing      Unknown           Unknown              0   \n",
      "2             Mina      Unknown              Male             88   \n",
      "5        Professor      Unknown              Male            127   \n",
      "7           Seward      Unknown              Male             71   \n",
      "8           Harker      Unknown              Male             96   \n",
      "9              God      Unknown              Male             87   \n",
      "11     Van_Helsing      Unknown           Unknown              0   \n",
      "12             Van      Unknown              Male            230   \n",
      "13         Quincey      Unknown              Male             59   \n",
      "14          Harker      Unknown              Male             96   \n",
      "15        Renfield      Unknown              Male             46   \n",
      "16          Seward      Unknown              Male             71   \n",
      "20  Quincey_Morris      Unknown           Unknown              0   \n",
      "21           Count      Unknown              Male            179   \n",
      "24     Mina_Harker      Unknown           Unknown              0   \n",
      "25        Westenra      Unknown              Male             17   \n",
      "26        Westenra      Unknown              Male             17   \n",
      "28         Hawkins      Unknown              Male             40   \n",
      "29         Dracula      Unknown              Male             41   \n",
      "30     Mina_Murray      Unknown           Unknown              0   \n",
      "\n",
      "    female_pronouns final_gender_contextual  \n",
      "1                 0                 Unknown  \n",
      "2                79                    Male  \n",
      "5                29                    Male  \n",
      "7                 7                    Male  \n",
      "8                52                    Male  \n",
      "9                43                    Male  \n",
      "11                0                 Unknown  \n",
      "12               96                    Male  \n",
      "13                5                    Male  \n",
      "14               52                    Male  \n",
      "15                3                    Male  \n",
      "16                7                    Male  \n",
      "20                0                 Unknown  \n",
      "21               40                    Male  \n",
      "24                0                 Unknown  \n",
      "25               15                    Male  \n",
      "26               15                    Male  \n",
      "28                2                    Male  \n",
      "29                0                    Male  \n",
      "30                0                 Unknown  \n",
      "\n",
      "New Gender Distribution (Contextual):\n",
      "final_gender_contextual\n",
      "Male       118\n",
      "Unknown     83\n",
      "Female      19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Apply Contextual Classification to 'Unknown' Characters\n",
    "\n",
    "if char_df is not None and sentences:\n",
    "    print(\"Applying contextual gender classification to 'Unknown' characters...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create new columns to store contextual results\n",
    "    char_df['contextual_gender'] = GENDER_UNKNOWN\n",
    "    char_df['male_pronouns'] = 0\n",
    "    char_df['female_pronouns'] = 0\n",
    "    char_df['context_mentions'] = 0\n",
    "\n",
    "    unknown_indices = char_df[char_df['final_gender'] == GENDER_UNKNOWN].index\n",
    "    print(f\"Found {len(unknown_indices)} characters initially marked as Unknown.\")\n",
    "\n",
    "    processed_count = 0\n",
    "    for index in unknown_indices:\n",
    "        char_name = char_df.loc[index, 'canonical_key']\n",
    "        variations = char_df.loc[index, 'variations']\n",
    "\n",
    "        # Skip overly short names or potential initials unlikely to be characters\n",
    "        # Also skip names that might be places often misidentified\n",
    "        # (Refine this list as needed)\n",
    "        if len(char_name) <= 2 and char_name.isupper() or char_name in ['Mr.', 'Mrs.', 'Longbourn', 'Netherfield', 'Pemberley', 'Hunsford', 'Rosings']:\n",
    "             continue\n",
    "\n",
    "        context_gender, m_count, f_count, mention_count = get_contextual_gender(\n",
    "            char_name,\n",
    "            variations,\n",
    "            sentences\n",
    "        )\n",
    "\n",
    "        # Update the dataframe\n",
    "        char_df.loc[index, 'contextual_gender'] = context_gender\n",
    "        char_df.loc[index, 'male_pronouns'] = m_count\n",
    "        char_df.loc[index, 'female_pronouns'] = f_count\n",
    "        char_df.loc[index, 'context_mentions'] = mention_count\n",
    "\n",
    "        processed_count += 1\n",
    "        if processed_count % 20 == 0:\n",
    "            print(f\"  Processed {processed_count}/{len(unknown_indices)} unknown characters...\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Contextual analysis finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Create a new 'final_gender_contextual' column\n",
    "    # If original final_gender was known, keep it. If it was unknown, use the new contextual one.\n",
    "    char_df['final_gender_contextual'] = char_df.apply(\n",
    "        lambda row: row['final_gender'] if row['final_gender'] != GENDER_UNKNOWN else row['contextual_gender'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    print(\"\\nUpdated gender classification results (showing previously Unknown):\")\n",
    "    context_changed = char_df[char_df.index.isin(unknown_indices)]\n",
    "    print(context_changed[['canonical_key', 'final_gender', 'contextual_gender', 'male_pronouns', 'female_pronouns', 'final_gender_contextual']].head(20))\n",
    "\n",
    "    print(\"\\nNew Gender Distribution (Contextual):\")\n",
    "    print(char_df['final_gender_contextual'].value_counts())\n",
    "else:\n",
    "    print(\"Skipping contextual classification due to missing input data (CSV or text).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving final contextually gendered character data to ../data/character_analysis_gendered_contextual_new.csv...\n",
      "Results saved successfully.\n",
      "\n",
      "--- Contextual Gender Classification Notebook Finished ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Save Final Results\n",
    "\n",
    "if char_df is not None:\n",
    "    print(f\"\\nSaving final contextually gendered character data to {OUTPUT_CSV_PATH}...\")\n",
    "    try:\n",
    "        # Ensure data directory exists\n",
    "        os.makedirs(os.path.dirname(OUTPUT_CSV_PATH), exist_ok=True)\n",
    "        # Select columns to save\n",
    "        columns_to_save = ['canonical_key', 'total_mentions', 'variation_count', 'variations', 'classified_gender', 'final_gender', # Original columns\n",
    "                           'contextual_gender', 'male_pronouns', 'female_pronouns', 'context_mentions', # Contextual analysis\n",
    "                           'final_gender_contextual'] # Final combined\n",
    "        # Reorder for clarity\n",
    "        final_df_to_save = char_df[columns_to_save].sort_values('total_mentions', ascending=False)\n",
    "\n",
    "        final_df_to_save.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "        print(\"Results saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping saving results due to previous errors.\")\n",
    "\n",
    "print(\"\\n--- Contextual Gender Classification Notebook Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aee0caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model and adding coreferee...\n",
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'coreferee']\n",
      "Loading data from ../data/character_analysis_gendered_contextual_new.csv...\n",
      "Loaded 220 characters.\n",
      "Loading text from ../data/dracula_cleaned.txt...\n",
      "Loaded text (848415 chars).\n",
      "Processing text with spaCy and coreferee (this can take time)...\n",
      "Text processing complete.\n",
      "Found 3742 coreference chains.\n",
      "Applying coreference results to Unknown characters...\n",
      "\\nCharacters re-classified using Coreference:\n",
      "    canonical_key final_gender_contextual coref_gender\n",
      "85         Hamlet                 Unknown         Male\n",
      "86    Shakespeare                 Unknown         Male\n",
      "114         Byron                 Unknown         Male\n",
      "173    Spencelagh                 Unknown         Male\n",
      "188        Caffyn                 Unknown         Male\n",
      "207      Disraeli                 Unknown         Male\n",
      "215       Olgaren                 Unknown         Male\n",
      "219     Bistritza                 Unknown       Female\n",
      "\n",
      "8 characters changed classification based on coreference.\n",
      "\n",
      "New Gender Distribution (Coreference):\n",
      "coref_gender\n",
      "Male       125\n",
      "Unknown     75\n",
      "Female      20\n",
      "Name: count, dtype: int64\n",
      "\\nSaving final coreference-based gendered character data to ../data/character_analysis_gendered_coref_new_1.csv...\n",
      "Results saved successfully.\n",
      "\\n--- Coreference Gender Classification Attempt Finished ---\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import coreferee # Import coreferee\n",
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "GENDERED_CONTEXT_CSV_PATH = \"../data/character_analysis_gendered_contextual_new.csv\" # Input from Notebook 02b\n",
    "CLEANED_TEXT_PATH = \"../data/dracula_cleaned.txt\" # Input from Notebook 00\n",
    "OUTPUT_CSV_PATH = \"../data/character_analysis_gendered_coref_new_1.csv\"\n",
    "GENDER_FEMALE = \"Female\"\n",
    "GENDER_MALE = \"Male\"\n",
    "GENDER_UNKNOWN = \"Unknown\"\n",
    "MALE_PRONOUNS = {'he', 'him', 'his'}\n",
    "FEMALE_PRONOUNS = {'she', 'her', 'hers'}\n",
    "\n",
    "# --- Load spaCy model and add coreferee ---\n",
    "print(\"Loading spaCy model and adding coreferee...\")\n",
    "\n",
    "# Using 'en_core_web_lg' perchÃ© 'en_core_web_trf' caused memory issues\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# Add the coreferee pipe\n",
    "# Coreferee automatically initializes when added if needed.\n",
    "nlp.add_pipe('coreferee')\n",
    "print(\"Pipeline:\", nlp.pipe_names)\n",
    "\n",
    "# --- Load Data ---\n",
    "print(f\"Loading data from {GENDERED_CONTEXT_CSV_PATH}...\")\n",
    "try:\n",
    "    char_df = pd.read_csv(GENDERED_CONTEXT_CSV_PATH)\n",
    "    print(f\"Loaded {len(char_df)} characters.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    char_df = None\n",
    "\n",
    "print(f\"Loading text from {CLEANED_TEXT_PATH}...\")\n",
    "try:\n",
    "    with open(CLEANED_TEXT_PATH, 'r', encoding='utf-8') as f:\n",
    "        full_text = f.read()\n",
    "    print(f\"Loaded text ({len(full_text)} chars).\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading text: {e}\")\n",
    "    full_text = None\n",
    "\n",
    "# --- Process the full text ---\n",
    "doc = None\n",
    "if full_text:\n",
    "    print(\"Processing text with spaCy and coreferee (this can take time)...\")\n",
    "    # Increase max_length if your text is very long\n",
    "    # nlp.max_length = len(full_text) + 100 # Consider adjusting if needed, but lg model is less demanding\n",
    "    doc = nlp(full_text)\n",
    "    print(\"Text processing complete.\")\n",
    "    # --- Access Coreference Chains ---\n",
    "    if doc._.coref_chains:\n",
    "         print(f\"Found {len(doc._.coref_chains)} coreference chains.\")\n",
    "         # Example: Print the first few chains\n",
    "         # doc._.coref_chains.print() # coreferee has a built-in print method\n",
    "    else:\n",
    "         print(\"No coreference chains found by coreferee.\")\n",
    "\n",
    "# --- Apply Coref Results to Gender Classification (Conceptual) ---\n",
    "if char_df is not None and doc is not None and doc._.coref_chains:\n",
    "    print(\"Applying coreference results to Unknown characters...\")\n",
    "    # Create a map from mention spans (start_token_index) to their chain index\n",
    "    mention_to_chain_index = {}\n",
    "    for chain_index, chain in enumerate(doc._.coref_chains):\n",
    "        for mention in chain:\n",
    "             # A mention in coreferee is a list of token indices\n",
    "             # CORRECTED: Access the first token index directly from the mention object\n",
    "             if mention: # Ensure mention is not empty (shouldn't happen but safe check)\n",
    "                 start_token_index = mention[0]\n",
    "                 mention_to_chain_index[start_token_index] = chain_index\n",
    "\n",
    "    # Create a map to store aggregated gender evidence per chain\n",
    "    chain_gender_evidence = {i: {'male': 0, 'female': 0, 'known_gender': GENDER_UNKNOWN} for i in range(len(doc._.coref_chains))}\n",
    "\n",
    "\n",
    "    known_char_gender = {}\n",
    "    for index, row in char_df[char_df['final_gender_contextual'] != GENDER_UNKNOWN].iterrows():\n",
    "        gender = row['final_gender_contextual']\n",
    "        variations = set(var.strip().lower() for var in str(row['variations']).split(','))\n",
    "        variations.add(row['canonical_key'].lower())\n",
    "        for var in variations:\n",
    "            if var:\n",
    "                known_char_gender[var] = gender\n",
    "\n",
    "\n",
    "    for chain_index, chain in enumerate(doc._.coref_chains):\n",
    "        for mention in chain:\n",
    "             # CORRECTED: Get span using mention indices directly\n",
    "             if not mention: continue # Skip empty mentions\n",
    "             mention_span = doc[mention[0]:mention[-1]+1]\n",
    "             mention_text = mention_span.text.lower()\n",
    "\n",
    "             # Check against known gendered characters\n",
    "             if mention_text in known_char_gender and chain_gender_evidence[chain_index]['known_gender'] == GENDER_UNKNOWN:\n",
    "                  chain_gender_evidence[chain_index]['known_gender'] = known_char_gender[mention_text]\n",
    "             # You might want more robust logic if a chain contains conflicting known characters\n",
    "\n",
    "             # Count pronouns (check the text of the mention span)\n",
    "             if mention_text in MALE_PRONOUNS:\n",
    "                 chain_gender_evidence[chain_index]['male'] += 1\n",
    "             if mention_text in FEMALE_PRONOUNS:\n",
    "                 chain_gender_evidence[chain_index]['female'] += 1\n",
    "\n",
    "    # --- Pass 2: Classify 'Unknown' characters based on their chain's evidence ---\n",
    "    char_df['coref_gender'] = char_df['final_gender_contextual'] # Start with previous best guess\n",
    "    unknown_indices = char_df[char_df['coref_gender'] == GENDER_UNKNOWN].index\n",
    "\n",
    "    for index in unknown_indices:\n",
    "        char_name = char_df.loc[index, 'canonical_key']\n",
    "        # Ensure variations are lowercase for matching\n",
    "        variations = set(var.strip().lower() for var in str(char_df.loc[index, 'variations']).split(','))\n",
    "        variations.add(char_name.lower())\n",
    "        variations.discard('') # Remove empty strings if any\n",
    "\n",
    "        # Find mentions of this character in the doc\n",
    "        found_chain_indices = set()\n",
    "        # This part is tricky: Need to map character name back to mentions found by coreferee\n",
    "        # A simple approach: iterate through all mentions in all chains\n",
    "        for chain_index, chain in enumerate(doc._.coref_chains):\n",
    "             for mention in chain:\n",
    "                 # CORRECTED: Get span using mention indices directly\n",
    "                 if not mention: continue\n",
    "                 mention_span = doc[mention[0]:mention[-1]+1]\n",
    "                 # Match against lowercase variations\n",
    "                 if mention_span.text.lower() in variations:\n",
    "                     found_chain_indices.add(chain_index)\n",
    "                     # Optimization: Once found in a chain, you might not need to check other mentions in the same chain\n",
    "                     # break # Uncomment if you only care if the char exists *anywhere* in the chain\n",
    "\n",
    "        # Aggregate evidence from all chains this character belongs to\n",
    "        final_male = 0\n",
    "        final_female = 0\n",
    "        final_known = GENDER_UNKNOWN\n",
    "        # Use a simple majority for known gender if conflicts arise\n",
    "        known_genders_found = []\n",
    "\n",
    "        for chain_idx in found_chain_indices:\n",
    "             evidence = chain_gender_evidence[chain_idx]\n",
    "             final_male += evidence['male']\n",
    "             final_female += evidence['female']\n",
    "             if evidence['known_gender'] != GENDER_UNKNOWN:\n",
    "                 known_genders_found.append(evidence['known_gender'])\n",
    "\n",
    "        # Determine final known gender (simple majority or fallback)\n",
    "        if known_genders_found:\n",
    "            from collections import Counter\n",
    "            gender_counts = Counter(known_genders_found)\n",
    "            # If one gender is clearly dominant, use it. Otherwise, could remain Unknown or use pronoun counts.\n",
    "            most_common = gender_counts.most_common(1)\n",
    "            if most_common:\n",
    "                # Simple approach: take the most common known gender found across chains\n",
    "                 final_known = most_common[0][0]\n",
    "            # More complex logic could be added here for tie-breaking or ambiguity\n",
    "\n",
    "\n",
    "        # Apply classification logic based on aggregated evidence\n",
    "        new_gender = GENDER_UNKNOWN\n",
    "        if final_known != GENDER_UNKNOWN:\n",
    "             new_gender = final_known\n",
    "        # Add thresholds similar to the previous notebook?\n",
    "        elif final_male > final_female: # Simple comparison for now\n",
    "             new_gender = GENDER_MALE\n",
    "        elif final_female > final_male:\n",
    "             new_gender = GENDER_FEMALE\n",
    "        # If counts are equal and no known gender, stays Unknown\n",
    "\n",
    "        char_df.loc[index, 'coref_gender'] = new_gender\n",
    "\n",
    "    # --- Display/Save Results ---\n",
    "    print(\"\\\\nCharacters re-classified using Coreference:\")\n",
    "    # Show changes...\n",
    "    changes = char_df[char_df['final_gender_contextual'] != char_df['coref_gender']]\n",
    "    print(changes[['canonical_key', 'final_gender_contextual', 'coref_gender']].head(20))\n",
    "    print(f\"\\n{len(changes)} characters changed classification based on coreference.\")\n",
    "    print(\"\\nNew Gender Distribution (Coreference):\")\n",
    "    print(char_df['coref_gender'].value_counts())\n",
    "\n",
    "    # Save results - Ensure OUTPUT_CSV_PATH is defined\n",
    "    if OUTPUT_CSV_PATH:\n",
    "        print(f\"\\\\nSaving final coreference-based gendered character data to {OUTPUT_CSV_PATH}...\")\n",
    "        try:\n",
    "            import os\n",
    "            os.makedirs(os.path.dirname(OUTPUT_CSV_PATH), exist_ok=True)\n",
    "            # Decide which columns to save\n",
    "            output_columns = ['canonical_key', 'total_mentions', 'variations',\n",
    "                              'final_gender_contextual', # Gender after context\n",
    "                              'coref_gender'] # Gender after coref\n",
    "            # Add other relevant columns as needed\n",
    "            final_coref_df = char_df[output_columns].sort_values('total_mentions', ascending=False)\n",
    "            final_coref_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "            print(\"Results saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {e}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Skipping coreference application due to missing data or coref chains.\")\n",
    "\n",
    "print(\"\\\\n--- Coreference Gender Classification Attempt Finished ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
